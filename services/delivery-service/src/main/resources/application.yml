server:
  port: 8088
  tomcat:
    accesslog:
      enabled: false

spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/delivery
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}
  jpa:
    hibernate:
      ddl-auto: update
    properties:
      hibernate.jdbc.time_zone: UTC

  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9094}
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL:http://localhost:8081}
      # FOR PROD - Connection & Timeout Settings
      request.timeout.ms: ${KAFKA_REQUEST_TIMEOUT:30000}
      retry.backoff.ms: ${KAFKA_RETRY_BACKOFF:100}
      reconnect.backoff.ms: ${KAFKA_RECONNECT_BACKOFF:50}
      connections.max.idle.ms: ${KAFKA_CONNECTIONS_MAX_IDLE:540000}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      # FOR PROD - Reliability Settings
      acks: ${KAFKA_PRODUCER_ACKS:all}
      retries: ${KAFKA_PRODUCER_RETRIES:2147483647}
      enable-idempotence: ${KAFKA_PRODUCER_IDEMPOTENCE:true}
      # FOR PROD - Performance Settings (optimized for food delivery)
      batch-size: ${KAFKA_PRODUCER_BATCH_SIZE:8192}
      linger-ms: ${KAFKA_PRODUCER_LINGER_MS:1}
      compression-type: ${KAFKA_PRODUCER_COMPRESSION:snappy}
      buffer-memory: ${KAFKA_PRODUCER_BUFFER_MEMORY:33554432}
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        specific.avro.reader: true
        # FOR PROD - Session management
        session.timeout.ms: ${KAFKA_CONSUMER_SESSION_TIMEOUT:30000}
        heartbeat.interval.ms: ${KAFKA_CONSUMER_HEARTBEAT_INTERVAL:3000}
      # FOR PROD - Reliability Settings
      auto-offset-reset: ${KAFKA_CONSUMER_OFFSET_RESET:earliest}
      enable-auto-commit: ${KAFKA_CONSUMER_AUTO_COMMIT:false}
      # FOR PROD - Performance Settings (optimized for food delivery)
      max-poll-records: ${KAFKA_CONSUMER_MAX_POLL_RECORDS:100}
      fetch-min-size: ${KAFKA_CONSUMER_FETCH_MIN_BYTES:1}
      fetch-max-wait: ${KAFKA_CONSUMER_FETCH_MAX_WAIT:100}
    listener:
      missing-topics-fatal: ${KAFKA_LISTENER_MISSING_TOPICS_FATAL:false}
      # FOR PROD - Listener Settings (optimized for food delivery)
      ack-mode: manual_immediate
      concurrency: ${KAFKA_LISTENER_CONCURRENCY:5}
      poll-timeout: ${KAFKA_LISTENER_POLL_TIMEOUT:1000}

  mvc:
    log-request-details: false

#Kafka configuration
kafka:
  consumer:
    group-id: ${KAFKA_CONSUMER_GROUP_ID:delivery-service}
  topics:
    # Topic configuration
    partitions: ${KAFKA_TOPIC_PARTITIONS:3}
    replicas: ${KAFKA_TOPIC_REPLICAS:1}
    # Consumer topics
    delivery-requested: ${KAFKA_TOPIC_DELIVERY_REQUESTED:fd.delivery.requested.v1}
    order-cancelled: ${KAFKA_TOPIC_ORDER_CANCELLED:fd.order.cancelled.v1}
    # Producer topics
    courier-assigned: ${KAFKA_TOPIC_COURIER_ASSIGNED:fd.delivery.courier-assigned.v1}
    order-picked-up: ${KAFKA_TOPIC_ORDER_PICKED_UP:fd.delivery.picked-up.v1}
    order-delivered: ${KAFKA_TOPIC_ORDER_DELIVERED:fd.delivery.delivered.v1}
  retry:
    attempts: ${KAFKA_RETRY_ATTEMPTS:3}
    delay: ${KAFKA_RETRY_DELAY:1000}
    multiplier: ${KAFKA_RETRY_MULTIPLIER:2.0}
    max-delay: ${KAFKA_RETRY_MAX_DELAY:10000}

management:
  endpoints:
    web:
      exposure:
        include: health,info

security:
  jwt:
    jwks-uri: ${JWT_JWKS_URI:http://localhost:8082/.well-known/jwks.json}

logging:
  level:
    root: INFO
    com.example.food: INFO
    org.springframework.kafka: INFO
    org.springframework.kafka.listener: INFO
    org.apache.kafka: WARN
    org.hibernate.SQL: INFO
    org.hibernate.orm.jdbc.bind: INFO
    org.springframework.security: INFO
    org.springframework.web: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level [%X{rid}] [%t] %logger{36} - %msg%n"
